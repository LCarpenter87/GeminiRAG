{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Create your own Q&A System Using Python: Build a RAG Model for Answering Questions from ePubs with Gemini\" at GDG London Google I/O Extended 2024"
      ],
      "metadata": {
        "id": "jmA33tAuWXSH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a workshop .ipynb designed to teach you the concepts of RAG. It is not formatted optimally or using best practice for working with Python or building for production! It is designed to help you learn the concepts and experience the code!\n",
        "\n",
        "Some code exists only to demonstrate a concept and serves no purpose to the overall project"
      ],
      "metadata": {
        "id": "GnIhxfNbzVcx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "0.   Play with embeddings for a second\n",
        "1.   Read in our EPub -> We're using pride and prejduice\n",
        "2.   Parse the documents\n",
        "3.   Use Recursive Character Text Splitting to CHUNK it\n",
        "4.   Embed the chunks"
      ],
      "metadata": {
        "id": "T37KsFwE-W5n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set-Up\n",
        "Pip install and imports"
      ],
      "metadata": {
        "id": "EqpJDpxT-N9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ebooklib"
      ],
      "metadata": {
        "collapsed": true,
        "id": "mRK1F0hlZx7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-text-splitters"
      ],
      "metadata": {
        "collapsed": true,
        "id": "To56xWzkZ0En"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb"
      ],
      "metadata": {
        "collapsed": true,
        "id": "C1alJ_pTZ2RB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google.generativeai"
      ],
      "metadata": {
        "collapsed": true,
        "id": "vOVeugo9XNbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0R3edeNXWEEc"
      },
      "outputs": [],
      "source": [
        "###############------------------ GEN AI tools\n",
        "import google.generativeai as genai\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "###############------------------ GEN AI tools\n",
        "import chromadb\n",
        "from chromadb import Client\n",
        "from chromadb.config import Settings\n",
        "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
        "\n",
        "###############------------------ Google Colab\n",
        "from google.colab import userdata\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "###############------------------ Ebook tools\n",
        "from ebooklib import epub\n",
        "import ebooklib\n",
        "from bs4 import BeautifulSoup\n",
        "import html\n",
        "\n",
        "###############------------------ General tools\n",
        "import pickle\n",
        "import requests\n",
        "from typing import List, Dict\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## If you have a Google API key for AI, insert as a secret called 'GOOGLE_API_KEY'!\n",
        "## If you have no key, don't worry -> we have some pre-build things for you =)\n",
        "\n",
        "try:\n",
        "  GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "  with_key = True\n",
        "  genai.configure(api_key=GOOGLE_API_KEY)\n",
        "  print(\"Success, have loaded your key!\")\n",
        "except:\n",
        "  with_key = False\n",
        "  print(\"We didn't find a key -> we'll use the pickle files of what we did earlier! \")"
      ],
      "metadata": {
        "id": "7xnPb8uRWv6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part Zero -> Let's see an embedding!"
      ],
      "metadata": {
        "id": "Er1MmpMraMOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if with_key:\n",
        "  result = genai.embed_content(\n",
        "  model=\"models/text-embedding-004\",\n",
        "  content=\"Workshops are fun!!!\",\n",
        "  task_type=\"retrieval_document\")\n",
        "  print('embedded content live')\n",
        "\n",
        "if not with_key:\n",
        "  print('Found No key, using the pickled version')\n",
        "  result = pickle.loads(requests.get('https://github.com/LCarpenter87/GeminiRAG/raw/main/result.pkl').content)"
      ],
      "metadata": {
        "id": "y8pXYqdhaQrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result['embedding'])"
      ],
      "metadata": {
        "id": "qix9DhbygpEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part One -> Read in the Epub\n"
      ],
      "metadata": {
        "id": "YpCNQx0DdL4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Download the book from GitHub\n",
        "book_url = 'https://github.com/LCarpenter87/GeminiRAG/raw/main/pap.epub'\n",
        "response = requests.get(book_url)\n",
        "\n",
        "with open('temp.epub', 'wb') as temp_file:\n",
        "    temp_file.write(response.content)\n",
        "\n",
        "# Read the EPUB book\n",
        "book = epub.read_epub('temp.epub', {'ignore_ncx': True})\n",
        "\n",
        "# Get the documents from the book (updated search)\n",
        "items = list(book.get_items_of_type(ebooklib.ITEM_DOCUMENT))\n"
      ],
      "metadata": {
        "id": "xggtQCoqhjGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## We can explore a little of the content -> it's HTML!\n",
        "items[0].get_body_content()[:500]"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ftWfhXXCoLAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part Two -> Parse the content from the ebook"
      ],
      "metadata": {
        "id": "fZPZARowzSx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def document_to_str(document):\n",
        "    \"\"\"Ingest a chapter object from the Ebook, and strip and clean it up\"\"\"\n",
        "    soup = BeautifulSoup(document.get_body_content(), 'html.parser')\n",
        "    text = [para.get_text(separator=' ', strip=True) for para in soup.find_all('p')]\n",
        "    clean_text = ' '.join(text)\n",
        "    clean_text = clean_text.replace('\\n', ' ')  # Remove newlines\n",
        "    clean_text = html.unescape(clean_text)  # Unescape HTML entities\n",
        "    clean_text = clean_text.replace(\"&#x27;\", \"'\")\n",
        "    clean_text = clean_text.replace(\"&#39;\", \"'\")\n",
        "    clean_text = ' '.join(clean_text.split())  # Remove extra spaces\n",
        "    return clean_text\n",
        "\n",
        "example = document_to_str(items[1])\n",
        "print(example)\n"
      ],
      "metadata": {
        "id": "5Bewr8BIpGXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Apply the function to every document in our items\n",
        "\n",
        "whole_book = [document_to_str(x) for x in items]"
      ],
      "metadata": {
        "id": "0ES5cPrpqJfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part Three -> Separate our contents into Chunks!"
      ],
      "metadata": {
        "id": "pkHSLg9U-B_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://python.langchain.com/v0.1/docs/modules/data_connection/document_transformers/\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=50,\n",
        "    length_function=len,\n",
        "    is_separator_regex=False,\n",
        ")\n",
        "\n",
        "texts = text_splitter.create_documents(whole_book)"
      ],
      "metadata": {
        "id": "8CgZx2c1_taJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(texts[2])"
      ],
      "metadata": {
        "id": "UZTT5uK1_tcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Big improvement opportunity -> We lost A LOT of meta data by stripping our HTML! Recursive is very basic. We could use a HTML based parser instead!\n",
        "\n"
      ],
      "metadata": {
        "id": "KvSdHD-oCiCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = {i:x.page_content for i,x in enumerate(texts)}"
      ],
      "metadata": {
        "id": "MhyArZEC_tg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part Four -> Create a local database using Chroma, to hold our embeddings and also return the content!"
      ],
      "metadata": {
        "id": "LruGMI26L4LY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
        "    def __call__(self, input: Documents) -> Embeddings:\n",
        "        genai.configure(api_key=GOOGLE_API_KEY)\n",
        "        model = \"models/text-embedding-004\"\n",
        "        title = \"Custom query\"\n",
        "        return genai.embed_content(model=model, content=input, task_type=\"retrieval_document\", title=title)[\"embedding\"]\n",
        "\n",
        "def set_up_chroma_db(path: str, name: str):\n",
        "    chroma_client = chromadb.PersistentClient(path=path)\n",
        "    try:\n",
        "        db = chroma_client.get_collection(name=name, embedding_function=GeminiEmbeddingFunction())\n",
        "        print(\"DB loaded\")\n",
        "    except ValueError:\n",
        "        db = chroma_client.create_collection(name=name, embedding_function=GeminiEmbeddingFunction())\n",
        "        print(\"DB created\")\n",
        "    return db\n",
        "\n",
        "path = \"/content/drive/MyDrive/Extended_Workshop\"\n",
        "name = \"Pride_and_prejudice_QA\"\n",
        "db = set_up_chroma_db(path, name)"
      ],
      "metadata": {
        "id": "bjkvIrSi_tlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lets Check Costs and Tokens!"
      ],
      "metadata": {
        "id": "kzsefIh8qsz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if with_key:\n",
        "  model_info = genai.get_model('models/text-embedding-004')\n",
        "  print(model_info.input_token_limit)"
      ],
      "metadata": {
        "id": "WtBZSkmyqlrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if with_key:\n",
        "  model = genai.GenerativeModel('models/gemini-1.5-flash')\n",
        "  print(model.count_tokens(example))"
      ],
      "metadata": {
        "id": "MeBXszSEq6ML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## This is the price per characters from the vertex AI pricing info site\n",
        "price_per_1000_characters = 0.000025\n",
        "price = len(example) / 1000 * price_per_1000_characters\n",
        "print(f'Price for the chapter ${price:.3f}')\n",
        "print(f'Price for the whole book approx ${(price * len(items)):.3f}')"
      ],
      "metadata": {
        "id": "8XvolwxWrf7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part Five -> Add the embeddings to the database in batches!"
      ],
      "metadata": {
        "id": "xUvh4udbSjru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_to_chroma_db_in_batches(db: chromadb.Collection, texts: Dict[int, str], book_title: str, batch_size: int, start_index: int = 0):\n",
        "    \"\"\"Adds documents to Chroma DB in batches with metadata and persists changes after each batch.\"\"\"\n",
        "\n",
        "    num_docs = len(texts)\n",
        "    for i in range(start_index, num_docs, batch_size):\n",
        "        batch_keys = list(texts.keys())[i:i + batch_size]\n",
        "        batch_docs = [texts[key] for key in batch_keys]\n",
        "\n",
        "        # Prepare IDs and metadata for the batch\n",
        "        ids = [str(key) for key in batch_keys]\n",
        "        metadatas = [{\"book_title\": book_title} for _ in batch_keys]\n",
        "\n",
        "        try:\n",
        "            # Add to Chroma DB (embedding is handled automatically)\n",
        "            db.add(\n",
        "                documents=batch_docs,\n",
        "                ids=ids,\n",
        "                metadatas=metadatas,\n",
        "            )\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error adding batch {i}-{i + batch_size}: {e}\")\n",
        "\n",
        "\n",
        "        print(f\"Added {min(i + batch_size, num_docs)} out of {num_docs} documents\")\n"
      ],
      "metadata": {
        "id": "jqwV0qabSkBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "short_texts = {k:v for k,v in texts.items() if k in range(0,10)}"
      ],
      "metadata": {
        "id": "Hg-7-kNlu64d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## To add all of them\n",
        "add_to_chroma_db_in_batches(db, short_texts, \"Pride and Prejudice\", 100, 0)"
      ],
      "metadata": {
        "id": "Wz9zsB-vSkIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part Six -> Querying the database!"
      ],
      "metadata": {
        "id": "MWJz7gInAW3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Lets see what passages we get back!\n",
        "\n",
        "db.query(query_texts=[\"What are the names of Mrs Bennet's daughters?\"])"
      ],
      "metadata": {
        "id": "2bE1bns_-iVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_relevant_passage(query, db, n_results):\n",
        "  passage = db.query(query_texts=[query], n_results=n_results)['documents']\n",
        "  passages = [' '.join(doc) for doc in passage]\n",
        "  passage = ' '.join(passages)\n",
        "  return passage"
      ],
      "metadata": {
        "id": "sENfFA5VA01-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_rag_prompt(query, relevant_passage):\n",
        "  escaped = relevant_passage.replace(\"'\", \"\").replace('\"', \"\").replace(\"\\n\", \" \")\n",
        "  prompt = (f\"\"\"You are a helpful and informative bot that answers questions using text from the reference passage included below. \\\n",
        "  Only use information given in the passage information, answering as fully as possible using the information provided.\n",
        "  \\You can paraphrase the passage or extrapolate if necessary. If the information is not given at all in the passage say \"i do not know\".\n",
        "\n",
        "  The answer should be well written, and be straight to the point.\n",
        "  It should not include any of the passage given.\n",
        "  QUESTION: '{query}'\n",
        "  PASSAGES: '{escaped}'\n",
        "\n",
        "  ANSWER:\n",
        "  \"\"\")\n",
        "  return prompt"
      ],
      "metadata": {
        "id": "m7xYCYUYA4pz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answer_genai(prompt):\n",
        "    generation_config = {\n",
        "      \"temperature\": 1,\n",
        "      \"top_p\": 0.95,\n",
        "      \"top_k\": 64,\n",
        "      \"max_output_tokens\": 8192,\n",
        "      \"response_mime_type\": \"text/plain\",\n",
        "    }\n",
        "    gemini_api_key = userdata.get('GOOGLE_API_KEY')\n",
        "    genai.configure(api_key=gemini_api_key)\n",
        "    model = genai.GenerativeModel('gemini-1.5-flash', generation_config=generation_config)\n",
        "    answer = model.generate_content(prompt)\n",
        "    return answer.text"
      ],
      "metadata": {
        "id": "jQzZlpfkA_hV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answer(db,query):\n",
        "    relevant_text = get_relevant_passage(query,db, n_results = 5)\n",
        "    prompt = make_rag_prompt(query,\n",
        "                             relevant_passage=\"\".join(relevant_text)) # joining the relevant chunks to create a single passage\n",
        "    answer = generate_answer_genai(prompt)\n",
        "\n",
        "    return answer.strip()"
      ],
      "metadata": {
        "id": "SnLa3NqSBUB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What are the names of Mrs Bennet's daughters?\"\n",
        "generate_answer(db,query)"
      ],
      "metadata": {
        "id": "Zrw7GtAMB36r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Who is considered to be very proud?\"\n",
        "generate_answer(db,query)"
      ],
      "metadata": {
        "id": "zowg7CNNCEDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Who does Elizabeth dislike from the first time they meet?\"\n",
        "generate_answer(db,query)"
      ],
      "metadata": {
        "id": "OciVOAJeCJln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Who elopes with Wickham?\"\n",
        "generate_answer(db,query)"
      ],
      "metadata": {
        "id": "H9z1BmtyCSmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Who saves Lydia from Mr.Wickham?\"\n",
        "generate_answer(db,query)"
      ],
      "metadata": {
        "id": "nzV_WZkyCzqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Who is the younger sibling of Mr.Darcy\"\n",
        "generate_answer(db,query)"
      ],
      "metadata": {
        "id": "uV5yQjUVC63w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Who is Mr.Darcy\"\n",
        "generate_answer(db,query)"
      ],
      "metadata": {
        "id": "jfoH6ywiDAex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is a truth universally acknowledged\"\n",
        "generate_answer(db,query)"
      ],
      "metadata": {
        "id": "qaLFyoJ-DEQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EX71fCZ8vKbh"
      }
    }
  ]
}